{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikodimov/arduino/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D1%81%D0%BB%D0%BE%D0%B9_(Dense)_%7C_%D0%94%D0%97_Ultra_Pro_%7C_%D0%A3%D0%98%D0%98%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swEDUwU6-S8x"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMJUXp5d-flR"
      },
      "source": [
        "Распознайте рукописную цифру, написанную на листе от руки.\n",
        "Последовательность шагов следующая:\n",
        "\n",
        "*   На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не \n",
        "более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).\n",
        "*   Фотографируем. Загружаем фото в Collaboratory.\n",
        "*   С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.\n",
        "*   С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.\n",
        "*   Выполняем инверсию цветов, нормирование и решейп массива.\n",
        "*   Выполняем распознавание собственной рукописной цифры.\n",
        "\n",
        "Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDCR1UFdqPUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000a45b9-827d-4b3a-ddfd-90d5871f90b7"
      },
      "source": [
        "# Ваше решение\n",
        "from tensorflow.keras.datasets import mnist     # Библиотека с базой рукописных цифр\n",
        "from tensorflow.keras.models import Sequential  # Подключение класса создания модели Sequential\n",
        "from tensorflow.keras.layers import Dense       # Подключение класса Dense - полносвязный слой\n",
        "from tensorflow.keras import utils              # Утилиты для подготовки данных\n",
        "import numpy as np                              # Работа с массивами\n",
        "import matplotlib.pyplot as plt                 # Отрисовка изображений\n",
        "#from google.colab import files                  # Работа с файлами\n",
        "from tensorflow.keras.preprocessing import image # Подключение библиотеки для загрузки изображений\n",
        "import os                                       # Подключение модуля для работы с файлами\n",
        "from PIL import Image \n",
        "\n",
        "# Отрисовка изображений в ячейках ноутбука\n",
        "%matplotlib inline \n",
        "\n",
        "# Загрузка из облака данных Mnist\n",
        "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()\n",
        "\n",
        "# Изменение формы входных картинок с 28х28 на 784\n",
        "# первая ось остается без изменения, остальные складываются в вектор\n",
        "x_train = x_train_org.reshape(x_train_org.shape[0], -1)   \n",
        "\n",
        "# Проверка результата\n",
        "print(f'Форма обучающих данных: {x_train_org.shape} -> {x_train.shape}')\n",
        "\n",
        "# Нормализация входных картинок\n",
        "# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "\n",
        "# Задание константы количества распознаваемых классов\n",
        "CLASS_COUNT = 10\n",
        "\n",
        "# Преобразование ответов в формат one_hot_encoding\n",
        "y_train = utils.to_categorical(y_train_org, CLASS_COUNT)\n",
        "y_test = utils.to_categorical(y_test_org, CLASS_COUNT)\n",
        "\n",
        "\n",
        "# Создание последовательной модели\n",
        "model = Sequential()\n",
        "\n",
        "# Добавление полносвязного слоя на 800 нейронов с relu-активацией\n",
        "model.add(Dense(800, input_dim=784, activation='relu')) \n",
        "\n",
        "# Добавление полносвязного слоя на 400 нейронов с relu-активацией\n",
        "model.add(Dense(400, activation='relu')) \n",
        "\n",
        "# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией\n",
        "model.add(Dense(CLASS_COUNT, activation='softmax')) \n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Вывод структуры модели\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма обучающих данных: (60000, 28, 28) -> (60000, 784)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 800)               628000    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 400)               320400    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 952,410\n",
            "Trainable params: 952,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.2033 - accuracy: 0.9397\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0762 - accuracy: 0.9764\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0484 - accuracy: 0.9850\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0352 - accuracy: 0.9886\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0254 - accuracy: 0.9918\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0217 - accuracy: 0.9926\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0181 - accuracy: 0.9939\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0204 - accuracy: 0.9931\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0131 - accuracy: 0.9957\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0123 - accuracy: 0.9959\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0094 - accuracy: 0.9970\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0106 - accuracy: 0.9966\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0108 - accuracy: 0.9965\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0113 - accuracy: 0.9966\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0112 - accuracy: 0.9965\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0052 - accuracy: 0.9983\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0075 - accuracy: 0.9976\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0064 - accuracy: 0.9981\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0027 - accuracy: 0.9993\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0101 - accuracy: 0.9969\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0071 - accuracy: 0.9980\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0083 - accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0042 - accuracy: 0.9986\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 6.7017e-04 - accuracy: 0.9998\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 3.8791e-04 - accuracy: 0.9999\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 3.1721e-05 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.5795e-05 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 9.2016e-06 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 7.1778e-06 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 5.7003e-06 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 4.5391e-06 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 3.6468e-06 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 2.9243e-06 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 2.3389e-06 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 1.8671e-06 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.4747e-06 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.1816e-06 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 9.3821e-07 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 7.3985e-07 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 5.8546e-07 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 4.6444e-07 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 3.6591e-07 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 2.8954e-07 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 2.2599e-07 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 1.7690e-07 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.3791e-07 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.0513e-07 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 8.0170e-08 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f21b3db6550>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к директории с базой\n",
        "base_dir = '/content'\n",
        "img_name = 'num_6.bmp'\n",
        "# Задание высоты и ширины загружаемых изображений\n",
        "img_height = 28\n",
        "img_width = 28\n",
        "\n",
        "# Загрузить распознаваемое изображение\n",
        "img_org = image.load_img(base_dir + '/' + img_name, \n",
        "                        target_size=(img_height, img_width), \n",
        "                        color_mode='grayscale')\n",
        "\n",
        "# Отобразить загруженную картинку\n",
        "plt.imshow(img_org, cmap='gray')\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# Преобразовать изображение в numpy-массив \n",
        "img = image.img_to_array(img_org)\n",
        "\n",
        "# Добавление одной оси в начале, чтобы нейронка могла распознать пример\n",
        "# Массив из одного примера, так как нейронка принимает именно массивы примеров (батчи) для распознавания\n",
        "img_norm = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Изменение формы входных картинок с 28х28 на 784\n",
        "# первая ось остается без изменения, остальные складываются в вектор\n",
        "img_norm1 = img.reshape(img_norm.shape[0], -1)   \n",
        "\n",
        "# Преобразование в тип float32 (числа с плавающей точкой) и нормализация\n",
        "img_norm1 = img_norm1.astype('float32') / 255.\n",
        "\n",
        "# Проверка формы данных\n",
        "#print(img_norm1.shape)\n",
        "\n",
        "# Распознавание примера\n",
        "prediction = model.predict(img_norm1) \n",
        "\n",
        "# Вывод результата - вектор из 10 чисел\n",
        "print(prediction)\n",
        "\n",
        "# Найти максимальное число \n",
        "max_value = np.amax(prediction)\n",
        "# Найти индекс максимального числа \n",
        "max_index = np.argmax(prediction)\n",
        "\n",
        "# Вывести результаты распознавания\n",
        "print()\n",
        "print('Распознанно число: ', max_index)\n",
        "print('Вероятность:       ', max_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "tCDNJ54uKOac",
        "outputId": "5620ca5f-a4a2-4e0d-b712-caeba6676e24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "[[4.13781058e-15 7.07176635e-12 1.13740616e-23 6.95006481e-17\n",
            "  1.52393244e-26 1.05096787e-01 8.94895017e-01 8.25752250e-06\n",
            "  2.25354170e-18 1.84015128e-17]]\n",
            "\n",
            "Распознанно число:  6\n",
            "Вероятность:        0.894895\n"
          ]
        }
      ]
    }
  ]
}